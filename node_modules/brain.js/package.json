{
  "_args": [
    [
      {
        "raw": "brain.js@^1.4.2",
        "scope": null,
        "escapedName": "brain.js",
        "name": "brain.js",
        "rawSpec": "^1.4.2",
        "spec": ">=1.4.2 <2.0.0",
        "type": "range"
      },
      "C:\\Users\\Dell\\Documents\\GitHub\\AMSOB"
    ]
  ],
  "_from": "brain.js@^1.4.2",
  "_hasShrinkwrap": false,
  "_id": "brain.js@1.4.2",
  "_location": "/brain.js",
  "_nodeVersion": "8.9.4",
  "_npmOperationalInternal": {
    "host": "s3://npm-registry-packages",
    "tmp": "tmp/brain.js_1.4.2_1538489902182_0.6528799781811159"
  },
  "_npmUser": {
    "name": "robertleeplummerjr",
    "email": "robertleeplummerjr@gmail.com"
  },
  "_npmVersion": "6.1.0",
  "_phantomChildren": {},
  "_requested": {
    "raw": "brain.js@^1.4.2",
    "scope": null,
    "escapedName": "brain.js",
    "name": "brain.js",
    "rawSpec": "^1.4.2",
    "spec": ">=1.4.2 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/brain.js/-/brain.js-1.4.2.tgz",
  "_shasum": "5c39539fdbe7f1a2eff6a7f4b3c70ec156de31fc",
  "_shrinkwrap": null,
  "_spec": "brain.js@^1.4.2",
  "_where": "C:\\Users\\Dell\\Documents\\GitHub\\AMSOB",
  "author": {
    "name": "Heather Arthur",
    "email": "fayearthur@gmail.com"
  },
  "bugs": {
    "url": "https://github.com/brainjs/brain.js/issues"
  },
  "collective": {
    "type": "opencollective",
    "url": "https://opencollective.com/brainjs"
  },
  "dependencies": {
    "gpu.js": "^1.2.0",
    "thaw.js": "^2.0.0"
  },
  "description": "Neural network library",
  "devDependencies": {
    "babel-cli": "^6.18.0",
    "babel-core": "^6.14.0",
    "babel-plugin-transform-object-rest-spread": "^6.8.0",
    "babel-polyfill": "^6.13.0",
    "babel-preset-es2015": "^6.14.0",
    "browserify": "^13.1.0",
    "js-datasets-iris": "^1.0.4",
    "licensify": "^3.1.2",
    "mocha": "^3.0.2",
    "rimraf": "^2.6.2",
    "sinon": "^1.17.6",
    "testee": "^0.7.0",
    "uglifyify": "^3.0.2"
  },
  "directories": {
    "test": "test"
  },
  "dist": {
    "integrity": "sha512-2BhcgKyFAZLoOmXt5vhc9xKbh9z64h02Yw9rS0NGoIHOGQH919EZhQMbtU6OVUfEgSbwJDXS0zScjSkg8qiJEw==",
    "shasum": "5c39539fdbe7f1a2eff6a7f4b3c70ec156de31fc",
    "tarball": "https://registry.npmjs.org/brain.js/-/brain.js-1.4.2.tgz",
    "fileCount": 190,
    "unpackedSize": 2545985,
    "npm-signature": "-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v3.0.4\r\nComment: https://openpgpjs.org\r\n\r\nwsFcBAEBCAAQBQJbs34vCRA9TVsSAnZWagAAGrQP/0V7zSBCIHaDxP20UG0c\nWTXJhMkusCFLMb60gPVj/wkUZ7AkoMrAiLdttazDUqQ8gtT8Xevzw9kYVf3/\nvsDtaIUtmeXekxNEOdRhvgJ7gdvD14OpaCl/FFCnnCn/wahJBbc68IHkRcfw\nZRybiPs2QhZhuARslEDWVY8NW+grRH3Tc0SJzchl7xvQxV0VP3MEnd2DIqf+\nB0bxdePVYEFTeA/x8iIQk6pp6QJCo+4+n/Los3BvuVkbKREIWZHarHRIrbkf\nhEMnEyzqawGjfioIKmXvDsq84yMvQTD2XKHXn+cqtoLZ9Y0w4A8Md3Kfxupv\nGWbvSociyFkPXNybOlo/RA/rjzFl0p+B+2xNbaUtrd2zmTi8xvljgV/8Nnc1\nlXPlYpqcl8FzImzQcRZt00Xu5Uz77gZZsh4DWmVJAdoZaW1vKnxzSRLj09C/\n+X+zp+qVz/THNwnt2RSS7dgVlRIY74eLg7iK5furp7lQSAZHIhRzII0jD7Rv\nru6CtFEH/5ai8d/Z8Za9+XzDFJ0Otlvo2kztqzH/ppXJw2H+a+Js90yxu1y/\nuiXkLi1GRUlILCzqpMyGY2csjQcGGVsSUieaymDBbdFPw1z3CgryvH+b5EXp\n1D39k5H0EzMnGuIN7bAK55DFvIkltk6fvtf+2B11Eo6NvetfFHvXu/KpuR8j\n79pR\r\n=RGeg\r\n-----END PGP SIGNATURE-----\r\n"
  },
  "gitHead": "fc48ae6b7e6ab6cb67257c1a155970c2a3d5e32b",
  "homepage": "https://github.com/brainjs/brain.js#readme",
  "keywords": [
    "ai",
    "artificial-intelligence",
    "brain",
    "brainjs",
    "brain.js",
    "feed forward",
    "neural network",
    "classifier",
    "neural",
    "network",
    "neural-networks",
    "machine-learning",
    "synapse",
    "recurrent",
    "long short term memory",
    "gated recurrent unit",
    "time series",
    "time step",
    "prediction",
    "rnn",
    "lstm",
    "gru"
  ],
  "license": "MIT",
  "main": "./index.js",
  "maintainers": [
    {
      "name": "ionicabizau",
      "email": "bizauionica@gmail.com"
    },
    {
      "name": "perkyguy",
      "email": "garrett.a.scott@gmail.com"
    },
    {
      "name": "robertleeplummerjr",
      "email": "robertleeplummerjr@gmail.com"
    }
  ],
  "name": "brain.js",
  "optionalDependencies": {},
  "readme": "\n# brain.js\n\n<img src=\"https://cdn.rawgit.com/harthur-org/brain.js/ff595242/logo.svg\" alt=\"Logo\" width=200px/>\n\n[![npm](https://img.shields.io/npm/dt/brain.js.svg?style=flat-square)](https://npmjs.com/package/brain.js) \n[![Backers on Open Collective](https://opencollective.com/brainjs/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/brainjs/sponsors/badge.svg)](#sponsors) \n\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/brain-js/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![Slack](https://slack.bri.im/badge.svg)](https://slack.bri.im)\n\n## About\n\n`brain.js` is a library of [Neural Networks](http://en.wikipedia.org/wiki/Artificial_neural_network) written in JavaScript.\n\n:bulb: **Note**: This is a continuation of the [**harthur/brain**](https://github.com/harthur/brain) repository (which is not maintained anymore). For more details, check out [this issue](https://github.com/harthur/brain/issues/72).\n\n## Table of Contents\n\n- [Examples](#examples)\n    + [More Examples](#more-examples)\n- [Usage](#usage)\n    + [Node](#node)\n    + [Browser](#browser)\n- [Training](#training)\n    + [Data format](#data-format)\n      + [For training with NeuralNetwork](#for-training-with-neuralnetwork)\n      + [For training with `RNNTimeStep`, `LSTMTimeStep` and `GRUTimeStep`](#for-training-with-rnntimestep-lstmtimestep-and-grutimestep)\n      + [For training with `RNN`, `LSTM` and `GRU`](#for-training-with-rnn-lstm-and-gru)\n    + [Training Options](#training-options)\n    + [Async Training](#async-training)\n    + [Cross Validation](#cross-validation)\n    + [Train Stream](#train-stream)\n- [Methods](#methods)\n    + [train](#train)\n- [Failing](#failing)\n- [JSON](#json)\n- [Options](#options)\n    + [activation](#activation)\n    + [hiddenLayers](#hiddenlayers)\n- [Streams](#streams)\n    + [Example](#example)\n    + [Initialization](#initialization)\n    + [Transform](#transform)\n- [Utilities](#utilities)\n    + [`likely`](#likely)\n- [Neural Network Types](#neural-network-types)\n    + [Why different Neural Network Types?](#why-different-neural-network-types)\n    \n# Examples\nHere's an example showcasing how to approximate the XOR function using `brain.js`:\nmore info on config [here](https://github.com/BrainJS/brain.js/blob/develop/src/neural-network.js#L31).\n\n```javascript\n// provide optional config object (or undefined). Defaults shown.\nconst config = {\n    binaryThresh: 0.5,     // ¬Ø\\_(„ÉÑ)_/¬Ø\n    hiddenLayers: [3],     // array of ints for the sizes of the hidden layers in the network\n    activation: 'sigmoid'  // supported activation types: ['sigmoid', 'relu', 'leaky-relu', 'tanh']\n};\n\n// create a simple feed forward neural network with backpropagation\nconst net = new brain.NeuralNetwork(config);\n\nnet.train([{input: [0, 0], output: [0]},\n           {input: [0, 1], output: [1]},\n           {input: [1, 0], output: [1]},\n           {input: [1, 1], output: [0]}]);\n\nconst output = net.run([1, 0]);  // [0.987]\n```\nor\nmore info on config [here](https://github.com/BrainJS/brain.js/blob/develop/src/recurrent/rnn.js#L726).\n\n```javascript\n// provide optional config object, defaults shown.\nconst config = {\n    inputSize: 20,\n    inputRange: 20,\n    hiddenSizes: [20,20],\n    outputSize: 20,\n    learningRate: 0.01,\n    decayRate: 0.999,\n};\n\n// create a simple recurrent neural network\nconst net = new brain.recurrent.RNN(config);\n\nnet.train([{input: [0, 0], output: [0]},\n           {input: [0, 1], output: [1]},\n           {input: [1, 0], output: [1]},\n           {input: [1, 1], output: [0]}]);\n\nlet output = net.run([0, 0]);  // [0]\noutput = net.run([0, 1]);      // [1]\noutput = net.run([1, 0]);      // [1]\noutput = net.run([1, 1]);      // [0]\n```\n\nHowever, there is no reason to use a neural network to figure out XOR. (-: So, here is a more involved, realistic example:\n[Demo: training a neural network to recognize color contrast](https://brain.js.org/).\n\n## More Examples\nYou can check out this fantastic screencast, which explains how to train a simple neural network using a real world dataset: [How to create a neural network in the browser using Brain.js](https://scrimba.com/c/c36zkcb).\n* [writing a children's book using a recurrent neural network](./examples/childrens-book.js)\n* [simple letter detection](./examples/which-letter-simple.js)\n\n# Usage\n\n### Node\nIf you have [node](http://nodejs.org/), you can install `brain.js` with [npm](http://npmjs.org):\n\n```\nnpm install brain.js\n```\n\nOr if you prefer yarn:\n```\nyarn add brain.js\n```\n\nAt present, the published version of brain.js is approximately 1.0.0, featuring only Feed-forward NN. All other models are beta and are being jazzed up and battle hardened.\nYou can still download the latest, though. They are cool!\n\n### Browser\nDownload the latest [brain.js for browser](https://cdn.rawgit.com/BrainJS/brain.js/master/browser.js). Training is computationally expensive, so you should try to train the network offline (or on a Worker) and use the `toFunction()` or `toJSON()` options to plug the pre-trained network into your website.\n\n# Training\nUse `train()` to train the network with an array of training data. The network has to be trained with all the data in bulk in one call to `train()`. More training patterns will probably take longer to train, but will usually result in a network better\nat classifying new patterns.\n\n### Data format\n#### For training with `NeuralNetwork`\nEach training pattern should have an `input` and an `output`, both of which can be either an array of numbers from `0` to `1` or a hash of numbers from `0` to `1`. For the [color contrast demo](https://brain.js.org/) it looks something like this:\n\n```javascript\nvar net = new brain.NeuralNetwork();\n\nnet.train([{input: { r: 0.03, g: 0.7, b: 0.5 }, output: { black: 1 }},\n           {input: { r: 0.16, g: 0.09, b: 0.2 }, output: { white: 1 }},\n           {input: { r: 0.5, g: 0.5, b: 1.0 }, output: { white: 1 }}]);\n\nvar output = net.run({ r: 1, g: 0.4, b: 0 });  // { white: 0.99, black: 0.002 }\n```\nHere's another variation of the above example. (_Note_ that input objects do not need to be similar.)\n```javascript\nnet.train([{input: { r: 0.03, g: 0.7 }, output: { black: 1 }},\n           {input: { r: 0.16, b: 0.2 }, output: { white: 1 }},\n           {input: { r: 0.5, g: 0.5, b: 1.0 }, output: { white: 1 }}]);\n\nvar output = net.run({ r: 1, g: 0.4, b: 0 });  // { white: 0.81, black: 0.18 }\n```\n\n#### For training with `RNNTimeStep`, `LSTMTimeStep` and `GRUTimeStep`\nEach training pattern can either:\n* Be an array of numbers\n* Be an array of arrays of numbers\n\nExample using an array of numbers:\n```javascript\nvar net = new brain.recurrent.LSTMTimeStep();\n\nnet.train([\n  [1, 2, 3]\n]);\n\nvar output = net.run([1, 2]);  // 3\n```\n\nExample using an array of arrays of numbers:\n```javascript\nvar net = new brain.recurrent.LSTMTimeStep();\n\nnet.train([\n  [1, 3],\n  [2, 2],\n  [3, 1],\n]);\n\nvar output = net.run([[1, 3], [2, 2]]);  // [3, 1]\n```\n\n#### For training with `RNN`, `LSTM` and `GRU`\nEach training pattern can either:\n* Be an array of values\n* Be a string\n* Have an `input` and an `output`\n  * Either of which can an array of values or a string\n\nCAUTION: When using an array of values, you can use ANY value, however, the values are represented in the neural network by a single input.  So the more _distinct values_ has _the larger your input layer_.  If you have a hundreds, thousands, or millions of floating point values _THIS IS NOT THE RIGHT CLASS FOR THE JOB_.  Also, when deviating from strings, this gets into beta\n\nExample using direct strings:\n```javascript\nvar net = new brain.recurrent.LSTM();\n\nnet.train([\n  'doe, a deer, a female deer',\n  'ray, a drop of golden sun',\n  'me, a name I call myself',\n]);\n\nvar output = net.run('doe');  // ', a deer, a female deer'\n```\n\nExample using strings with inputs and outputs:\n```javascript\nvar net = new brain.recurrent.LSTM();\n\nnet.train([\n  { input: 'I feel great about the world!', output: 'happy' },\n  { input: 'The world is a terrible place!', output: 'sad' },\n]);\n\nvar output = net.run('I feel great about the world!');  // 'happy'\n```\n\n\n### Training Options\n`train()` takes a hash of options as its second argument:\n\n```javascript\nnet.train(data, {\n                            // Defaults values --> expected validation\n      iterations: 20000,    // the maximum times to iterate the training data --> number greater than 0\n      errorThresh: 0.005,   // the acceptable error percentage from training data --> number between 0 and 1\n      log: false,           // true to use console.log, when a function is supplied it is used --> Either true or a function\n      logPeriod: 10,        // iterations between logging out --> number greater than 0\n      learningRate: 0.3,    // scales with delta to effect training rate --> number between 0 and 1\n      momentum: 0.1,        // scales with next layer's change value --> number between 0 and 1\n      callback: null,       // a periodic call back that can be triggered while training --> null or function\n      callbackPeriod: 10,   // the number of iterations through the training data between callback calls --> number greater than 0\n      timeout: Infinity     // the max number of milliseconds to train for --> number greater than 0\n});\n```\n\nThe network will stop training whenever one of the two criteria is met: the training error has gone below the threshold (default `0.005`), or the max number of iterations (default `20000`) has been reached.\n\nBy default training will not let you know how it's doing until the end, but set `log` to `true` to get periodic updates on the current training error of the network. The training error should decrease every time. The updates will be printed to console. If you set `log` to a function, this function will be called with the updates instead of printing to the console.\n\nThe learning rate is a parameter that influences how quickly the network trains. It's a number from `0` to `1`. If the learning rate is close to `0`, it will take longer to train. If the learning rate is closer to `1`, it will train faster, but training results may be constrained to a local minimum and perform badly on new data.(_Overfitting_) The default learning rate is `0.3`.\n\nThe momentum is similar to learning rate, expecting a value from `0` to `1` as well, but it is multiplied against the next level's change value. The default value is `0.1`\n\nAny of these training options can be passed into the constructor or passed into the `updateTrainingOptions(opts)` method and they will be saved on the network and used during the training time. If you save your network to json, these training options are saved and restored as well (except for callback and log, callback will be forgotten and log will be restored using console.log).\n\nA boolean property called `invalidTrainOptsShouldThrow` is set to `true` by default. While the option is `true`, if you enter a training option that is outside the normal range, an error will be thrown with a message about the abnormal option. When the option is set to `false`, no error will be sent, but a message will still be sent to `console.warn` with the related information.\n\n### Async Training\n`trainAsync()` takes the same arguments as train (data and options). Instead of returning the results object from training, it returns a promise that when resolved will return the training results object.\n\n```javascript\n  let net = new brain.NeuralNetwork();\n  net\n    .trainAsync(data, options)\n    .then(res => {\n      // do something with my trained network\n    })\n    .catch(handleError);\n```\nWith multiple networks you can train in parallel like this:\n\n```javascript\n  const net = new brain.NeuralNetwork();\n  const net2 = new brain.NeuralNetwork();\n\n  const p1 = net.trainAsync(data, options);\n  const p2 = net2.trainAsync(data, options);\n\n  Promise\n    .all([p1, p2])\n    .then(values => {\n      const res = values[0];\n      const res2 = values[1];\n      console.log(`net trained in ${res.iterations} and net2 trained in ${res2.iterations}`);\n      // do something super cool with my 2 trained networks\n    })\n    .catch(handleError);\n```\n\n### Cross Validation\n[Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) can provide a less fragile way of training on larger data sets.  The brain.js api provides Cross Validation in this example:\n```js\nconst crossValidate = new brain.CrossValidate(brain.NeuralNetwork, networkOptions);\ncrossValidate.train(data, trainingOptions, k); //note k (or KFolds) is optional\nconst json = crossValidate.toJSON(); // all stats in json as well as neural networks\nconst net = crossValidate.toNeuralNetwork();\n\n\n// optionally later\nconst json = crossValidate.toJSON();\nconst net = crossValidate.fromJSON(json);\n```\n\nAn example of using cross validate can be found in [examples/cross-validate.js](examples/cross-validate.js)\n\n### Train Stream\nStreams are a very powerful tool in node for massive data spread across processes and are provided via the brain.js api in the following way: \n```js\nconst net = new brain.NeuralNetwork();\nconst trainStream = new brain.TrainStream({\n  neuralNetwork: net,\n  floodCallback: function() {\n    flood(trainStream, data);\n  },\n  doneTrainingCallback: function(stats) {\n    // network is done training!  What next?\n  }\n});\n\n// kick it off\nreadInputs(trainStream, data);\n\nfunction readInputs(stream, data) {\n  for (let i = 0; i < data.length; i++) {\n    stream.write(data[i]);\n  }\n  // let it know we've reached the end of the inputs\n  stream.endInputs();\n}\n```\n\nAn example of using train stream can be found in [examples/stream-example.js](examples/stream-example.js)\n\n# Methods\n### train\nThe output of `train()` is a hash of information about how the training went:\n\n```javascript\n{\n  error: 0.0039139985510105032,  // training error\n  iterations: 406                // training iterations\n}\n```\n\n# Failing\nIf the network failed to train, the error will be above the error threshold. This could happen if the training data is too noisy (most likely), the network does not have enough hidden layers or nodes to handle the complexity of the data, or it has not been trained for enough iterations.\n\nIf the training error is still something huge like `0.4` after 20000 iterations, it's a good sign that the network can't make sense of the given data.\n\n# JSON\nSerialize or load in the state of a trained network with JSON:\n\n```javascript\nconst json = net.toJSON();\nnet.fromJSON(json);\n```\n\nYou can also get a custom standalone function from a trained network that acts just like `run()`:\n\n```javascript\nconst run = net.toFunction();\nconst output = run({ r: 1, g: 0.4, b: 0 });\nconsole.log(run.toString()); // copy and paste! no need to import brain.js\n```\n\n# Options\n`NeuralNetwork()` takes a hash of options:\n\n```javascript\nconst net = new brain.NeuralNetwork({\n  activation: 'sigmoid', // activation function\n  hiddenLayers: [4],\n  learningRate: 0.6 // global learning rate, useful when training using streams\n});\n```\n\n### activation\nThis parameter lets you specify which activation function your neural network should use. There are currently four supported activation functions, **sigmoid** being the default: \n\n- [sigmoid](https://www.wikiwand.com/en/Sigmoid_function)\n- [relu](https://www.wikiwand.com/en/Rectifier_(neural_networks))\n- [leaky-relu](https://www.wikiwand.com/en/Rectifier_(neural_networks))\n- [tanh](https://theclevermachine.wordpress.com/tag/tanh-function/)\n\nHere's a table (thanks, Wikipedia!) summarizing a plethora of activation functions ‚Äî [Activation Function](https://www.wikiwand.com/en/Activation_function)\n\n### hiddenLayers\nYou can use this to specify the number of hidden layers in the network and the size of each layer. For example, if you want two hidden layers - the first with 3 nodes and the second with 4 nodes, you'd give:\n\n```\nhiddenLayers: [3, 4]\n```\n\nBy default `brain.js` uses one hidden layer with size proportionate to the size of the input array.\n\n# Streams\nThe network now has a [WriteStream](http://nodejs.org/api/stream.html#stream_class_stream_writable). You can train the network by using `pipe()` to send the training data to the network.\n\n\n### Example\nRefer to [`stream-example.js`](examples/stream-example.js) for an example on how to train the network with a stream.\n\n\n### Initialization\nTo train the network using a stream you must first create the stream by calling `net.createTrainStream()` which takes the following options:\n\n* `floodCallback()` - the callback function to re-populate the stream. This gets called on every training iteration.\n* `doneTrainingCallback(info)` - the callback function to execute when the network is done training. The `info` param will contain a hash of information about how the training went:\n\n```javascript\n{\n  error: 0.0039139985510105032,  // training error\n  iterations: 406                // training iterations\n}\n```\n\n### Transform\nUse a [Transform](http://nodejs.org/api/stream.html#stream_class_stream_transform) to coerce the data into the correct format. You might also use a Transform stream to normalize your data on the fly.\n\n# Utilities\n\n### `likely`\n\n```js\nconst likely = require('brain/likely');\nconst key = likely(input, net);\n```\n\nLikely example see: [simple letter detection](./examples/which-letter-simple.js)\n\n# Neural Network Types\n* [`brain.NeuralNetwork`](src/neural-network.js) - [Feedforward Neural Network](https://en.wikipedia.org/wiki/Feedforward_neural_network) with backpropagation\n* [`brain.recurrent.RNNTimeStep`](src/recurrent/rnn-time-step.js) - [Time Step Recurrent Neural Network or \"RNN\"](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n* [`brain.recurrent.LSTMTimeStep`](src/recurrent/lstm-time-step.js) - [Time Step Long Short Term Memory Neural Network or \"LSTM\"](https://en.wikipedia.org/wiki/Long_short-term_memory)\n* [`brain.recurrent.GRUTimeStep`](src/recurrent/gru-time-step.js) - [Time Step Gated Recurrent Unit or \"GRU\"](https://en.wikipedia.org/wiki/Gated_recurrent_unit)\n* [`brain.recurrent.RNN`](src/recurrent/rnn.js) - [Recurrent Neural Network or \"RNN\"](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n* [`brain.recurrent.LSTM`](src/recurrent/lstm.js) - [Long Short Term Memory Neural Network or \"LSTM\"](https://en.wikipedia.org/wiki/Long_short-term_memory)\n* [`brain.recurrent.GRU`](src/recurrent/gru.js) - [Gated Recurrent Unit or \"GRU\"](https://en.wikipedia.org/wiki/Gated_recurrent_unit)\n\n### Why different Neural Network Types?\nDifferent neural nets do different things well. For example:\n* A Feedforward Neural Network can classify simple things very well, but it has no memory of previous actions and has infinite variation of results.\n* A Time Step Recurrent Neural Network _remembers_, and can predict future values.\n* A Recurrent Neural Network _remembers_, and has a finite set of results.\n\n# Get Involved!\n\n### Issues\n\nIf you have an issue, either a bug or a feature you think would benefit your project let us know and we will do our best.\n\nCreate issues [here](https://github.com/BrainJS/brain.js/issues) and follow the template.\n\n### Contributors\n\nThis project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].\n<a href=\"graphs/contributors\"><img src=\"https://opencollective.com/brainjs/contributors.svg?width=890&button=false\" /></a>\n\n\n### Backers\n\nThank you to all our backers! üôè [[Become a backer](https://opencollective.com/brainjs#backer)]\n\n<a href=\"https://opencollective.com/brainjs#backers\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/backers.svg?width=890\"></a>\n\n\n### Sponsors\n\nSupport this project by becoming a sponsor. Your logo will show up here with a link to your website. [[Become a sponsor](https://opencollective.com/brainjs#sponsor)]\n\n<a href=\"https://opencollective.com/brainjs/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/brainjs/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/brainjs/sponsor/9/avatar.svg\"></a>\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+ssh://git@github.com/brainjs/brain.js.git"
  },
  "scripts": {
    "browser": "browserify ./index.js -p licensify -o browser.js -s brain",
    "browser-min": "browserify ./index.js -p licensify -s brain -g uglifyify -o browser.min.js",
    "clean": "rimraf node_modules",
    "dist": "babel src --out-dir dist --source-maps",
    "make": "rimraf dist && npm run dist && git add ./dist && npm run browser && npm run browser-min",
    "test": "npm run test-base && npm run test-utilities",
    "test-applications": "find ./test/applications -name '*.js' | xargs mocha --compilers js:babel-core/register",
    "test-base": "find ./test/base/ -name '*.js' | xargs mocha --compilers js:babel-core/register",
    "test-browser": "testee test/browser/index.html --browsers firefox --reporter Spec",
    "test-experimental": "npm run test-recurrent-matrix && npm run test-recurrent && npm run test-utilities",
    "test-gru": "find ./test/recurrent/ -name 'gru.js' | xargs mocha --compilers js:babel-core/register",
    "test-lstm": "find ./test/recurrent/ -name 'lstm.js' | xargs mocha --compilers js:babel-core/register",
    "test-recurrent": "find ./test/recurrent/ -name '*.js' | xargs mocha --compilers js:babel-core/register",
    "test-recurrent-matrix": "find ./test/recurrent/matrix -name '*.js' | xargs mocha --compilers js:babel-core/register",
    "test-rnn": "find ./test/recurrent/ -name 'rnn.js' | xargs mocha --compilers js:babel-core/register",
    "test-utilities": "find ./test/utilities/ -name '*.js' | xargs mocha --compilers js:babel-core/register"
  },
  "typings": "./index.d.ts",
  "version": "1.4.2"
}
